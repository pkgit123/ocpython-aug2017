{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peter Kim, OCPython Meetup - August 1, 2017\n",
    "PeopleSpace, Irvine, CA\n",
    "\n",
    "## Text Classification with Scikit-Learn\n",
    "\n",
    "YouTube Spam Collection\n",
    "\n",
    "The YouTube Spam Collection v. 1 is a public set of YouTube comments that have been collected for spam research. It has five datasets composed by 1,956 real and non-encoded messages that were labeled as legitimate (ham) or spam.\n",
    ">Alberto, T.C., Lochter J.V., Almeida, T.A. TubeSpam: Comment Spam Filtering on YouTube. Proceedings of the 14th IEEE International Conference on Machine Learning and Applications (ICMLA'15), 1-6, Miami, FL, USA, December, 2015. (preprint).  Available at: http://dcomp.sor.ufscar.br/talmeida/papers/TCA_ICMLA15.pdf\n",
    ">\n",
    "> Data Source: http://dcomp.sor.ufscar.br/talmeida/youtubespamcollection/\n",
    ">\n",
    ">Also available at UCI Machine Learning Repository.\n",
    "><br>Source: http://archive.ics.uci.edu/ml/datasets/YouTube+Spam+Collection#\n",
    "\n",
    "Download the zip files.  Make sure to include file \"Youtube04-Eminem.csv\" in same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python libraries\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import PorterStemmer\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dataframe with Eminem YouTube comments\n",
    "df_eminem = pd.read_csv(\"Youtube04-Eminem.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(448, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eminem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'COMMENT_ID', u'AUTHOR', u'DATE', u'CONTENT', u'CLASS'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eminem.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine dataframe \n",
    "{Class 0: ham, Class 1: spam}\n",
    "<br>'CONTENT' field is the comment, 'CONTENT' field is the class.\n",
    "<br>Ignore the other fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z12rwfnyyrbsefonb232i5ehdxzkjzjs2</td>\n",
       "      <td>Lisa Wellas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+447935454150 lovely girl talk to me xxx﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>z130wpnwwnyuetxcn23xf5k5ynmkdpjrj04</td>\n",
       "      <td>jason graham</td>\n",
       "      <td>2015-05-29T02:26:10.652000</td>\n",
       "      <td>I always end up coming back to this song&lt;br /&gt;﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>z13vsfqirtavjvu0t22ezrgzyorwxhpf3</td>\n",
       "      <td>Ajkal Khan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my sister just received over 6,500 new &lt;a rel=...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z12wjzc4eprnvja4304cgbbizuved35wxcs</td>\n",
       "      <td>Dakota Taylor</td>\n",
       "      <td>2015-05-29T02:13:07.810000</td>\n",
       "      <td>Cool﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z13xjfr42z3uxdz2223gx5rrzs3dt5hna</td>\n",
       "      <td>Jihad Naser</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hello I&amp;#39;am from Palastine﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            COMMENT_ID         AUTHOR  \\\n",
       "0    z12rwfnyyrbsefonb232i5ehdxzkjzjs2    Lisa Wellas   \n",
       "1  z130wpnwwnyuetxcn23xf5k5ynmkdpjrj04   jason graham   \n",
       "2    z13vsfqirtavjvu0t22ezrgzyorwxhpf3     Ajkal Khan   \n",
       "3  z12wjzc4eprnvja4304cgbbizuved35wxcs  Dakota Taylor   \n",
       "4    z13xjfr42z3uxdz2223gx5rrzs3dt5hna    Jihad Naser   \n",
       "\n",
       "                         DATE  \\\n",
       "0                         NaN   \n",
       "1  2015-05-29T02:26:10.652000   \n",
       "2                         NaN   \n",
       "3  2015-05-29T02:13:07.810000   \n",
       "4                         NaN   \n",
       "\n",
       "                                             CONTENT  CLASS  \n",
       "0          +447935454150 lovely girl talk to me xxx﻿      1  \n",
       "1    I always end up coming back to this song<br />﻿      0  \n",
       "2  my sister just received over 6,500 new <a rel=...      1  \n",
       "3                                              Cool﻿      0  \n",
       "4                     Hello I&#39;am from Palastine﻿      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine dataframe  {Class 0: ham, Class 1: spam}\n",
    "df_eminem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    245\n",
       "0    203\n",
       "Name: CLASS, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eminem['CLASS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ham     203\n",
       "Spam    245\n",
       "Name: CLASS, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_eminem['CLASS'].value_counts()\n",
    "# df_eminem['CLASS'].value_counts().rename(index={1: 'Spam', 0: 'Ham'})\n",
    "vc_class = df_eminem['CLASS'].value_counts()\n",
    "vc_class = vc_class.rename(index={1: 'Spam', 0: 'Ham'})\n",
    "vc_class = vc_class.sort_index()\n",
    "vc_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x126ef978>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEOCAYAAACHE9xHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAIz7X2CbsLdCNHpHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12698b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hist(bins=bins, grid=False); plt.xticks([0,1])\n",
    "vc_class.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split the Content and Classes into train and test sets (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_eminem['CONTENT'], df_eminem['CLASS'], \n",
    "                                                    random_state=1, test_size=0.2, stratify=df_eminem['CLASS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X training size:  (358L,)\n",
      "y training size:  (358L,)\n",
      "X test size:  (90L,)\n",
      "y test size:  (90L,)\n"
     ]
    }
   ],
   "source": [
    "print 'X training size: ', X_train.shape\n",
    "print 'y training size: ', y_train.shape\n",
    "print 'X test size: ', X_test.shape\n",
    "print 'y test size: ', y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize Text into DTM (with Pre-Processing)\n",
    "* Pre-processing function\n",
    "* List comprehension with pre-processing function\n",
    "* LemmaTokenizer class\n",
    "* CountVectorizer object with LemmaTokenizer\n",
    "\n",
    "# Surprise: performs worse with pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Pre-processing from Kaggle tutorial\n",
    "\n",
    "# stop_nltk = stopwords.words(\"english\")\n",
    "# stop_nltk_plus = stop_nltk + [u'a',u'b',u'c',u'd',u'e',u'f',u'g',u'h',u'i',u'j',\n",
    "#                          u'k',u'l',u'm',u'n',u'o',u'p',u'q',u'r',u's',u't',\n",
    "#                          u'u',u'v',u'w',u'x',u'y',u'z']\n",
    "# # 4. In Python, searching a set is much faster than searching\n",
    "# #     a list, so convert the stop words to a set\n",
    "# stops = set(stop_nltk_plus)\n",
    "    \n",
    "# # function to process 10k documents\n",
    "# def process_10kchars(input_text):\n",
    "#     # 1. Remove non-letters, and make lowercase\n",
    "#     letters_only = re.sub(\"[^a-zA-Z]\", \" \", input_text)\n",
    "        \n",
    "#     # 3. Convert to lower case, split into individual words\n",
    "#     words = letters_only.lower().split()    \n",
    "    \n",
    "#     # 5. Remove stop words\n",
    "#     meaningful_words = [w for w in words if not w in stops]   \n",
    "    \n",
    "#     # 6. Join the words back into one string separated by space, \n",
    "#     # and return the result.\n",
    "#     return( \" \".join( meaningful_words ))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Wall time: 22.1 s\n",
    "\n",
    "# # list comprehension on X_train_chunks, with process_10kchars\n",
    "# X_train_process = [process_10kchars(text_file) for text_file in X_train]\n",
    "\n",
    "# X_test_process = [process_10kchars(text_file) for text_file in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # create a new CountVectorizer with lemmatizer\n",
    "# class LemmaTokenizer(object):\n",
    "#     def __init__(self):\n",
    "#         self.wnl = WordNetLemmatizer()\n",
    "#     def __call__(self, doc):\n",
    "#         return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
    "    \n",
    "# count_vect_lemma = CountVectorizer(tokenizer=LemmaTokenizer())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # instantiate CountVectorizer object, with LemmaTokenizer()\n",
    "# count_vect_lemma = CountVectorizer(tokenizer=LemmaTokenizer(), ngram_range=(1, 2), max_features=1000, \n",
    "#                                    max_df=0.90, stop_words='english') \n",
    "\n",
    "# # Fit the vectorizer object to the X_train text\n",
    "# X_train_vect = count_vect_lemma.fit(X_train_process, y_train)\n",
    "\n",
    "# # Transform the training text into a document-term-matrix\n",
    "# X_train_dtm = X_train_vect.transform(X_train_process)\n",
    "\n",
    "# print \"Size of training dtm: \", X_train_dtm.shape\n",
    "\n",
    "# # Transform the test text into a document-term-matrix (input fed into models)\n",
    "# X_test_dtm = X_train_vect.transform(X_test_process)\n",
    "\n",
    "# print \"Size of test dtm: \", X_test_dtm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize text into DTM (no pre-processing)\n",
    "* Leave text unprocessed, no lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training dtm:  (358, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a vectorizer for document-term-matrix\n",
    "vect = CountVectorizer(max_features=1000)\n",
    "\n",
    "# Fit the vectorizer object to the X_train text\n",
    "X_train_vect = vect.fit(X_train, y_train)\n",
    "\n",
    "# Transform the training text into a document-term-matrix\n",
    "X_train_dtm = X_train_vect.transform(X_train)\n",
    "\n",
    "print \"Size of training dtm: \", X_train_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test dtm:  (90, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Transform the test text into a document-term-matrix (input fed into models)\n",
    "X_test_dtm = X_train_vect.transform(X_test)\n",
    "\n",
    "print \"Size of test dtm: \", X_test_dtm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification Example Without GridSearchCV\n",
    "* In practice, the GridSearchCV class accomplishes same result, while tuning combinations of model parameters.\n",
    "* But to make it simpler to follow the workflow, here is an example of text classification step-by-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Instatiate a classifier object.\n",
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "# Step 2: \"Fit\" training data onto model, both data and labels.\n",
    "# The machine is \"learning\" how the training words match the label data (or \"classes\").  \n",
    "rf_clf.fit(X_train_dtm, y_train)\n",
    "\n",
    "# Step 3: Predict test data using model, only data (not labels)\n",
    "# Store results as predictions on test data ... next we will compare with real labels.  \n",
    "rf_test_predictions = rf_clf.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Random Forest Classifier: \")\n",
    "\n",
    "# print accuracy of class predictions\n",
    "print(metrics.accuracy_score(y_test, rf_test_predictions))\n",
    "\n",
    "# print the confusion matrix\n",
    "print(\"\\nConfusion Matrix: \")\n",
    "print(\"(rows are actual, columns are predictions)\")\n",
    "print(metrics.confusion_matrix(y_test, rf_test_predictions, labels=[\"Ham\", \"Spam\"]))\n",
    "\n",
    "# print the Classification Report\n",
    "print(\"\\nClassification Report: \")\n",
    "print(metrics.classification_report(y_test, rf_test_predictions,target_names=[\"Ham\", \"Spam\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Technique #1: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95251396648\n",
      "bootstrap: False\n",
      "class_weight: 'balanced'\n",
      "n_estimators: 50\n",
      "Wall time: 8.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Use GridSearchCV to tune model parameters\n",
    "\n",
    "# parameters \n",
    "parameters_rf = {'n_estimators': (10, 50, 100),                 # default 10\n",
    "                 'bootstrap': (True, False),                          # default true\n",
    "                  'class_weight': ('balanced', None)}                # default None\n",
    "\n",
    "# instantiate a classifier object\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# instantiate a GridSearchCV object\n",
    "gs_rf = GridSearchCV(rf, parameters_rf, n_jobs=-1)\n",
    "\n",
    "# fit the GridSearchCV object to the training data\n",
    "gs_rf = gs_rf.fit(X_train_dtm, y_train)\n",
    "\n",
    "print(gs_rf.best_score_)\n",
    "\n",
    "for param_name in sorted(parameters_rf.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_rf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier: \n",
      "0.955555555556\n",
      "[[40  1]\n",
      " [ 3 46]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        Ham       0.93      0.98      0.95        41\n",
      "       Spam       0.98      0.94      0.96        49\n",
      "\n",
      "avg / total       0.96      0.96      0.96        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Random Forest Classifier: \"\n",
    "\n",
    "# predict classification\n",
    "gs_rf_test_predictions = gs_rf.predict(X_test_dtm)\n",
    "\n",
    "# print accuracy of class predictions\n",
    "print(metrics.accuracy_score(y_test, gs_rf_test_predictions))\n",
    "\n",
    "# print the confusion matrix\n",
    "print(metrics.confusion_matrix(y_test, gs_rf_test_predictions))\n",
    "\n",
    "print(metrics.classification_report(y_test, gs_rf_test_predictions,target_names=[\"Ham\", \"Spam\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare Target Class Label Counts to Classification Report\n",
      "0: Ham, 1: Spam\n",
      "\n",
      "0    41\n",
      "1    49\n",
      "Name: CLASS, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verify classes against the y_test data\n",
    "print \"Compare Target Class Label Counts to Classification Report\"\n",
    "print \"0: Ham, 1: Spam\\n\"\n",
    "print y_test.value_counts(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification Technique #2: Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search for MultinomialNB\n",
      "Accuracy:  0.916201117318\n",
      "alpha:  0.1\n",
      "fit_prior:  False\n"
     ]
    }
   ],
   "source": [
    "# Use GridSearchCV to tune model parameters\n",
    "\n",
    "# parameters for MultinomialNB\n",
    "parameters_mnb = {'alpha': (0.001, 0.01, 0.1, 1.0, 10.0, 100.0),\n",
    "                 'fit_prior': (True, False)}    # default is True, use uniform if False\n",
    "\n",
    "# instantiate a MultinomialNB object\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# instantiate a GridSearchCV object\n",
    "gs_mnb = GridSearchCV(mnb, parameters_mnb, n_jobs=-1)\n",
    "\n",
    "# fit the GridSearchCV object to the training data\n",
    "gs_mnb = gs_mnb.fit(X_train_dtm, y_train)\n",
    "\n",
    "print \"Grid Search for MultinomialNB\"\n",
    "print \"Accuracy: \", gs_mnb.best_score_\n",
    "print \"alpha: \", gs_mnb.best_params_['alpha']\n",
    "print \"fit_prior: \", gs_mnb.best_params_['fit_prior']\n",
    "# for param_name in sorted(parameters.keys()):\n",
    "#     print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes: \n",
      "0.933333333333\n",
      "[[37  4]\n",
      " [ 2 47]]\n",
      "0.973618715779\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        Ham       0.95      0.90      0.92        41\n",
      "       Spam       0.92      0.96      0.94        49\n",
      "\n",
      "avg / total       0.93      0.93      0.93        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Multinomial Naive Bayes: \"\n",
    "\n",
    "# predict classification\n",
    "gs_mnb_test_predictions = gs_mnb.predict(X_test_dtm)\n",
    "\n",
    "# print accuracy of class predictions\n",
    "print(metrics.accuracy_score(y_test, gs_mnb_test_predictions))\n",
    "\n",
    "# print the confusion matrix\n",
    "print(metrics.confusion_matrix(y_test, gs_mnb_test_predictions))\n",
    "\n",
    "# calculate predicted probabilities (poorly calibrated)\n",
    "gs_y_pred_test = gs_mnb.predict_proba(X_test_dtm)[:, 1]\n",
    "\n",
    "# print AUC\n",
    "print(metrics.roc_auc_score(y_test, gs_y_pred_test))\n",
    "\n",
    "# print classification report\n",
    "print(metrics.classification_report(y_test, gs_mnb_test_predictions,target_names=[\"Ham\", \"Spam\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare Target Class Label Counts to Classification Report\n",
      "0: Ham, 1: Spam\n",
      "\n",
      "0    41\n",
      "1    49\n",
      "Name: CLASS, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verify classes against the y_test data\n",
    "print \"Compare Target Class Label Counts to Classification Report\"\n",
    "print \"0: Ham, 1: Spam\\n\"\n",
    "print y_test.value_counts(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Technique #3: Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.949720670391\n",
      "alpha: 0.01\n",
      "class_weight: 'balanced'\n",
      "penalty: 'elasticnet'\n",
      "Wall time: 3.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Use GridSearchCV to tune model parameters\n",
    "\n",
    "# parameters for SVM\n",
    "parameters_svm = {'penalty': (None, 'l1', 'l2', 'elasticnet'),  # default is 'l2'\n",
    "                  'alpha': (0.0001, 0.01, 1.0),                 # default 0.0001\n",
    "                  'class_weight': ('balanced', None)}           # default None\n",
    "\n",
    "# instantiate a SVM object\n",
    "svm = SGDClassifier(loss='hinge', random_state=42)\n",
    "\n",
    "# instantiate a GridSearchCV object\n",
    "gs_svm = GridSearchCV(svm, parameters_svm, n_jobs=-1)\n",
    "\n",
    "# fit the GridSearchCV object to the training data\n",
    "gs_svm = gs_svm.fit(X_train_dtm, y_train)\n",
    "\n",
    "print gs_svm.best_score_\n",
    "\n",
    "for param_name in sorted(parameters_svm.keys()):\n",
    "    print \"%s: %r\" % (param_name, gs_svm.best_params_[param_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machines: \n",
      "0.977777777778\n",
      "[[41  0]\n",
      " [ 2 47]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        Ham       0.95      1.00      0.98        41\n",
      "       Spam       1.00      0.96      0.98        49\n",
      "\n",
      "avg / total       0.98      0.98      0.98        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Support Vector Machines: \"\n",
    "\n",
    "# predict classification\n",
    "gs_svm_test_predictions = gs_svm.predict(X_test_dtm)\n",
    "\n",
    "# print accuracy of class predictions\n",
    "print(metrics.accuracy_score(y_test, gs_svm_test_predictions))\n",
    "\n",
    "# print the confusion matrix\n",
    "print(metrics.confusion_matrix(y_test, gs_svm_test_predictions))\n",
    "\n",
    "print(metrics.classification_report(y_test, gs_svm_test_predictions,target_names=[\"Ham\", \"Spam\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare Target Class Label Counts to Classification Report\n",
      "0: Ham, 1: Spam\n",
      "\n",
      "0    41\n",
      "1    49\n",
      "Name: CLASS, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verify classes against the y_test data\n",
    "print \"Compare Target Class Label Counts to Classification Report\"\n",
    "print \"0: Ham, 1: Spam\\n\"\n",
    "print y_test.value_counts(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Technique #4: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95530726257\n",
      "C: 1.0\n",
      "class_weight: None\n",
      "penalty: 'l2'\n",
      "Wall time: 3.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Use GridSearchCV to tune model parameters\n",
    "\n",
    "# parameters \n",
    "parameters_lr = {'penalty': ('l1', 'l2'),               # default is 'l2'\n",
    "                  'C': (0.01, 1.0, 10.0, 100.0),            # default 1.0\n",
    "                  'class_weight': ('balanced', None)}                         # default None\n",
    "\n",
    "# instantiate a LogisticRegression object\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# instantiate a GridSearchCV object\n",
    "gs_lr = GridSearchCV(lr, parameters_lr, n_jobs=-1)\n",
    "\n",
    "# fit the GridSearchCV object to the training data\n",
    "gs_lr = gs_lr.fit(X_train_dtm, y_train)\n",
    "\n",
    "print(gs_lr.best_score_)\n",
    "\n",
    "for param_name in sorted(parameters_lr.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_lr.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: \n",
      "0.966666666667\n",
      "[[41  0]\n",
      " [ 3 46]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        Ham       0.93      1.00      0.96        41\n",
      "       Spam       1.00      0.94      0.97        49\n",
      "\n",
      "avg / total       0.97      0.97      0.97        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Logistic Regression: \"\n",
    "\n",
    "# predict classification\n",
    "gs_lr_test_predictions = gs_lr.predict(X_test_dtm)\n",
    "\n",
    "# print accuracy of class predictions\n",
    "print(metrics.accuracy_score(y_test, gs_lr_test_predictions))\n",
    "\n",
    "# print the confusion matrix\n",
    "print(metrics.confusion_matrix(y_test, gs_lr_test_predictions))\n",
    "\n",
    "print(metrics.classification_report(y_test, gs_lr_test_predictions,target_names=[\"Ham\", \"Spam\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare Target Class Label Counts to Classification Report\n",
      "0: Ham, 1: Spam\n",
      "\n",
      "0    41\n",
      "1    49\n",
      "Name: CLASS, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verify classes against the y_test data\n",
    "print \"Compare Target Class Label Counts to Classification Report\"\n",
    "print \"0: Ham, 1: Spam\\n\"\n",
    "print y_test.value_counts(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Comparison of Models (w/o Pre-Processing, with GridSearch)\n",
    "\n",
    "(Precision, Recall, F1-Score for the Spam Class Only)\n",
    "\n",
    "| Model                    | Accuracy   | Precision    | Recall    | F1-Score    |\n",
    "|--------------------------|------------|--------------|-----------|-------------|\n",
    "| Random Forest            | 0.9555     | 0.98         | 0.94      | 0.96        |\n",
    "| Multinomial Naive Bayes  | 0.9333     | 0.92         | 0.96      | 0.94        |\n",
    "| Support Vector Machines  | 0.9778     | 1.00         | 0.96      | 0.98        |\n",
    "| Logistic Regression      | 0.9667     | 1.00         | 0.94      | 0.97        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

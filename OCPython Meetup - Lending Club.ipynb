{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peter Kim, OCPython Meetup - August 1, 2017\n",
    "PeopleSpace, Irvine, CA\n",
    "\n",
    "## Text Classification with Scikit-Learn\n",
    "Lending Club Dataset\n",
    ">Original Source: https://www.lendingclub.com/info/download-data.action\n",
    "><br>Kaggle Discussion: https://www.kaggle.com/wendykan/lending-club-loan-data\n",
    "\n",
    "## Inspiration Reference:\n",
    "When Words Sweat: Identifying Signals for Loan Default in the Text of Loan Applications\n",
    ">Netzer, Oded and Lemaire, Alain and Herzenstein, Michal, When Words Sweat: Identifying Signals for Loan Default in the Text of Loan Applications (November 6, 2016). Columbia Business School Research Paper No. 16-83. Available at SSRN: https://ssrn.com/abstract=2865327.  \n",
    "\n",
    "## Background References on Text Classification and Python/Scikit-Learn.\n",
    ">PyCon 2016 Tutorial from Data School, “Machine Learning with Text in scikit-learn (PyCon 2016),” by Kevin Markham on May 28, 2016. \n",
    "* YouTube Lecture Available at: https://www.youtube.com/watch?v=ZiKMIuYidY0  \n",
    "* Github Available at: https://github.com/justmarkham/pycon-2016-tutorial\n",
    ">\n",
    "><br> scikit-learn, “Working with Text Data”.  Available at: http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "<br>\n",
    "><br> Kaggle tutorial, “Bag of Words Meets Bags of Popcorn.”  December 9 2014 – June 30, 2015.  Available at: https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words\n",
    "<br>\n",
    "><br> scikit-learn, “Feature Extraction (Customizing the Vectorizer Class)”.  Available at: http://scikit-learn.org/stable/modules/feature_extraction.html\n",
    ">\n",
    "><br> Andreas Müller and Sarah Guido, \"Introduction to Machine Learning with Python,\" O'Reilly Media, October 2016.  Available at: http://shop.oreilly.com/product/0636920030515.do\n",
    ">\n",
    "><br> Sebastian Raschka, \"Python Machine Learning,\" Packt Publishing; 1 edition (September 23, 2015).  Available at: https://www.packtpub.com/big-data-and-business-intelligence/python-machine-learning\n",
    "\n",
    "## Note: This Jupyter notebook uses Python 3 (other one uses Python 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, HashingVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import PorterStemmer\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39786, 120)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Pandas Dataframe with Lending Club data from 2007-2011.\n",
    "# The \"2007-2011.csv\" file has been cleaned-up from original \"LoanStats3a.csv\".  \n",
    "df_lendingclub = pd.read_csv(\"2007-2011.csv\")\n",
    "\n",
    "# How many rows and columns?\n",
    "df_lendingclub.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>...</th>\n",
       "      <th>sec_app_earliest_cr_line</th>\n",
       "      <th>sec_app_inq_last_6mths</th>\n",
       "      <th>sec_app_mort_acc</th>\n",
       "      <th>sec_app_open_acc</th>\n",
       "      <th>sec_app_revol_util</th>\n",
       "      <th>sec_app_open_il_6m</th>\n",
       "      <th>sec_app_num_rev_accts</th>\n",
       "      <th>sec_app_chargeoff_within_12_mths</th>\n",
       "      <th>sec_app_collections_12_mths_ex_med</th>\n",
       "      <th>sec_app_mths_since_last_major_derog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65%</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27%</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>Ryder</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2400</td>\n",
       "      <td>2400</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96%</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49%</td>\n",
       "      <td>339.31</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>AIR RESOURCES BOARD</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.69%</td>\n",
       "      <td>67.79</td>\n",
       "      <td>B</td>\n",
       "      <td>B5</td>\n",
       "      <td>University Medical Group</td>\n",
       "      <td>1 year</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  funded_amnt  funded_amnt_inv        term int_rate  installment  \\\n",
       "0       5000         5000           4975.0   36 months   10.65%       162.87   \n",
       "1       2500         2500           2500.0   60 months   15.27%        59.83   \n",
       "2       2400         2400           2400.0   36 months   15.96%        84.33   \n",
       "3      10000        10000          10000.0   36 months   13.49%       339.31   \n",
       "4       3000         3000           3000.0   60 months   12.69%        67.79   \n",
       "\n",
       "  grade sub_grade                 emp_title emp_length  \\\n",
       "0     B        B2                       NaN  10+ years   \n",
       "1     C        C4                     Ryder   < 1 year   \n",
       "2     C        C5                       NaN  10+ years   \n",
       "3     C        C1       AIR RESOURCES BOARD  10+ years   \n",
       "4     B        B5  University Medical Group     1 year   \n",
       "\n",
       "                  ...                 sec_app_earliest_cr_line  \\\n",
       "0                 ...                                      NaN   \n",
       "1                 ...                                      NaN   \n",
       "2                 ...                                      NaN   \n",
       "3                 ...                                      NaN   \n",
       "4                 ...                                      NaN   \n",
       "\n",
       "   sec_app_inq_last_6mths sec_app_mort_acc sec_app_open_acc  \\\n",
       "0                     NaN              NaN              NaN   \n",
       "1                     NaN              NaN              NaN   \n",
       "2                     NaN              NaN              NaN   \n",
       "3                     NaN              NaN              NaN   \n",
       "4                     NaN              NaN              NaN   \n",
       "\n",
       "  sec_app_revol_util sec_app_open_il_6m  sec_app_num_rev_accts  \\\n",
       "0                NaN                NaN                    NaN   \n",
       "1                NaN                NaN                    NaN   \n",
       "2                NaN                NaN                    NaN   \n",
       "3                NaN                NaN                    NaN   \n",
       "4                NaN                NaN                    NaN   \n",
       "\n",
       "  sec_app_chargeoff_within_12_mths sec_app_collections_12_mths_ex_med  \\\n",
       "0                              NaN                                NaN   \n",
       "1                              NaN                                NaN   \n",
       "2                              NaN                                NaN   \n",
       "3                              NaN                                NaN   \n",
       "4                              NaN                                NaN   \n",
       "\n",
       "  sec_app_mths_since_last_major_derog  \n",
       "0                                 NaN  \n",
       "1                                 NaN  \n",
       "2                                 NaN  \n",
       "3                                 NaN  \n",
       "4                                 NaN  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure it loaded correctly.\n",
    "df_lendingclub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'term', 'int_rate', 'installment', 'grade', 'sub_grade', 'emp_title', 'emp_length', 'home_ownership', 'annual_inc', 'verification_status', 'issue_d', 'loan_status', 'pymnt_plan', 'url', 'desc', 'purpose', 'title', 'zip_code', 'addr_state', 'dti', 'delinq_2yrs', 'earliest_cr_line', 'inq_last_6mths', 'mths_since_last_delinq', 'mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'initial_list_status', 'out_prncp', 'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int', 'total_rec_late_fee', 'recoveries', 'collection_recovery_fee', 'last_pymnt_d', 'last_pymnt_amnt', 'next_pymnt_d', 'last_credit_pull_d', 'collections_12_mths_ex_med', 'mths_since_last_major_derog', 'policy_code', 'application_type', 'annual_inc_joint', 'dti_joint', 'verification_status_joint', 'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal', 'open_acc_6m', 'open_il_6m', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il', 'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util', 'total_rev_hi_lim', 'inq_fi', 'total_cu_tl', 'inq_last_12m', 'acc_open_past_24mths', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util', 'chargeoff_within_12_mths', 'delinq_amnt', 'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl', 'mort_acc', 'mths_since_recent_bc', 'mths_since_recent_bc_dlq', 'mths_since_recent_inq', 'mths_since_recent_revol_delinq', 'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl', 'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl', 'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m', 'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m', 'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pub_rec_bankruptcies', 'tax_liens', 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit', 'total_il_high_credit_limit', 'revol_bal_joint', 'sec_app_earliest_cr_line', 'sec_app_inq_last_6mths', 'sec_app_mort_acc', 'sec_app_open_acc', 'sec_app_revol_util', 'sec_app_open_il_6m', 'sec_app_num_rev_accts', 'sec_app_chargeoff_within_12_mths', 'sec_app_collections_12_mths_ex_med', 'sec_app_mths_since_last_major_derog']\n"
     ]
    }
   ],
   "source": [
    "# What are the columns?  \n",
    "print(list(df_lendingclub.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_amnt                                                           5000\n",
       "funded_amnt                                                         5000\n",
       "funded_amnt_inv                                                     4975\n",
       "term                                                           36 months\n",
       "int_rate                                                          10.65%\n",
       "installment                                                       162.87\n",
       "grade                                                                  B\n",
       "sub_grade                                                             B2\n",
       "emp_title                                                            NaN\n",
       "emp_length                                                     10+ years\n",
       "home_ownership                                                      RENT\n",
       "annual_inc                                                         24000\n",
       "verification_status                                             Verified\n",
       "issue_d                                                           Dec-11\n",
       "loan_status                                                   Fully Paid\n",
       "pymnt_plan                                                             n\n",
       "url                                                                  NaN\n",
       "desc                     Borrower added on 12/22/11 > I need to upgra...\n",
       "purpose                                                      credit_card\n",
       "title                                                           Computer\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine first record, first 20 columns.\n",
    "df_lendingclub.iloc[0, 0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  Borrower added on 12/22/11 > I need to upgrade my business technologies.<br>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine first record, 'desc'.\n",
    "df_lendingclub['desc'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fully Paid'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine first record, 'loan_status'.\n",
    "df_lendingclub['loan_status'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Descriptions From Lending Club Data Dictionary:\n",
    ">'desc': Loan description provided by the borrower\n",
    "<br>\n",
    "<br>'loan_status': Current status of the loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39786, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Borrower added on 12/22/11 &gt; I need to upgra...</td>\n",
       "      <td>Fully Paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Borrower added on 12/22/11 &gt; I plan to use t...</td>\n",
       "      <td>Charged Off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Fully Paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Borrower added on 12/21/11 &gt; to pay for prop...</td>\n",
       "      <td>Fully Paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Borrower added on 12/21/11 &gt; I plan on combi...</td>\n",
       "      <td>Fully Paid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                desc  loan_status\n",
       "0    Borrower added on 12/22/11 > I need to upgra...   Fully Paid\n",
       "1    Borrower added on 12/22/11 > I plan to use t...  Charged Off\n",
       "2                                                NaN   Fully Paid\n",
       "3    Borrower added on 12/21/11 > to pay for prop...   Fully Paid\n",
       "4    Borrower added on 12/21/11 > I plan on combi...   Fully Paid"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new dataframe with 2 columns: 'desc' and 'loan_status'\n",
    "df_text = df_lendingclub[['desc', 'loan_status']].copy()\n",
    "\n",
    "# How many rows and columns?\n",
    "print(df_text.shape)\n",
    "\n",
    "# See if it loaded correctly.\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loan Status of Total Loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of loans:  39786\n",
      "\n",
      "Total loans by loan status: \n",
      "Fully Paid     34116\n",
      "Charged Off     5670\n",
      "Name: loan_status, dtype: int64\n",
      "\n",
      "% of total loans by loan status: \n",
      "Fully Paid     0.857488\n",
      "Charged Off    0.142512\n",
      "Name: loan_status, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Total number of loans\n",
    "print(\"Total number of loans: \", df_text.shape[0])\n",
    "\n",
    "# How many are Fully Paid vs. Charged off?\n",
    "loan_status = df_text['loan_status'].value_counts()\n",
    "print(\"\\nTotal loans by loan status: \")\n",
    "print(loan_status)\n",
    "\n",
    "# What % of loans are Fully Paid?\n",
    "print(\"\\n% of total loans by loan status: \")\n",
    "print(loan_status/df_text.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loans  with Blank Descriptions by Loan Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loans with blank descriptions:  12966\n",
      "% of loans with blank descriptions:  0.325893530388\n",
      "\n",
      "Loans with blank descriptions by loan status: \n",
      "Fully Paid     11147\n",
      "Charged Off     1819\n",
      "Name: loan_status, dtype: int64\n",
      "\n",
      "% of loans with blank descriptions by loan status: \n",
      "Fully Paid     0.85971\n",
      "Charged Off    0.14029\n",
      "Name: loan_status, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# How many 'desc' fields are blank?\n",
    "blank_desc = df_text['desc'].isnull().sum()\n",
    "print(\"Number of loans with blank descriptions: \", blank_desc)\n",
    "print(\"% of loans with blank descriptions: \", blank_desc/df_text.shape[0])\n",
    "\n",
    "# Of the loans with blank descriptions, what is loan status?\n",
    "blank_loan_status = df_text[df_text['desc'].isnull()]['loan_status'].value_counts()\n",
    "print(\"\\nLoans with blank descriptions by loan status: \")\n",
    "print(blank_loan_status)\n",
    "\n",
    "# What % of loans with blank descriptions are Fully Paid?\n",
    "print(\"\\n% of loans with blank descriptions by loan status: \")\n",
    "print(blank_loan_status/blank_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only Loans with Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Borrower added on 12/22/11 &gt; I need to upgra...</td>\n",
       "      <td>Fully Paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Borrower added on 12/22/11 &gt; I plan to use t...</td>\n",
       "      <td>Charged Off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Borrower added on 12/21/11 &gt; to pay for prop...</td>\n",
       "      <td>Fully Paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Borrower added on 12/21/11 &gt; I plan on combi...</td>\n",
       "      <td>Fully Paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Borrower added on 12/18/11 &gt; I am planning o...</td>\n",
       "      <td>Fully Paid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                desc  loan_status\n",
       "0    Borrower added on 12/22/11 > I need to upgra...   Fully Paid\n",
       "1    Borrower added on 12/22/11 > I plan to use t...  Charged Off\n",
       "3    Borrower added on 12/21/11 > to pay for prop...   Fully Paid\n",
       "4    Borrower added on 12/21/11 > I plan on combi...   Fully Paid\n",
       "6    Borrower added on 12/18/11 > I am planning o...   Fully Paid"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only include loans with descriptions, use dropna() method.\n",
    "df_text_desc = df_text.dropna()\n",
    "df_text_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loans with a description:  26820\n",
      "\n",
      "Loans with descriptions by loan status: \n",
      "Fully Paid     22969\n",
      "Charged Off     3851\n",
      "Name: loan_status, dtype: int64\n",
      "\n",
      "% of loans with descriptions by loan status: \n",
      "Fully Paid     0.856413\n",
      "Charged Off    0.143587\n",
      "Name: loan_status, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# How many loans have a description?\n",
    "print(\"Number of loans with a description: \", df_text_desc.shape[0])\n",
    "\n",
    "# Loans with description by loan status?\n",
    "print(\"\\nLoans with descriptions by loan status: \")\n",
    "loan_status_desc = df_text_desc['loan_status'].value_counts()\n",
    "print(loan_status_desc)\n",
    "\n",
    "# What % of loans with descriptions are Fully Paid vs. Charged Off?\n",
    "print(\"\\n% of loans with descriptions by loan status: \")\n",
    "print(loan_status_desc/df_text_desc.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Very Important to Balance the Classes\n",
    "Particularly for high-dimensional, highly-sparse datasets\n",
    "> Blagus, Rok and Lusa, Lara, “SMOTE for high-dimensional class-imbalanced data,” BMC Bioinformatics, March 22, 2013.  Available at: https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-14-106\n",
    ">\n",
    "><br>Blagus, Rok and Lusa, Lara, “Class prediction for high-dimensional class-imbalanced data,” BMC Bioinformatics, October 20, 2010.  Available at: https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-11-523\n",
    ">\n",
    "><br>Alexander Yun-chung Liu, “The Effect of Oversampling and Undersampling on Classifying Imbalanced Text Datasets,” Thesis for M.S.E., The University of Texas at Austin, August 2004.  Available at: https://pdfs.semanticscholar.org/cade/435c88610820f073a0fb61b73dff8f006760.pdf\n",
    ">\n",
    "><br>Nick Becker Github page, “The Right Way to Oversample in Predictive Modeling,” December 23, 2016.  Available at: https://beckernick.github.io/oversampling-modeling/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d9afbf56a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEuCAYAAABlDd5YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIA4AAANxAAAY/h8JhYd0Ieg8ZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d9b09f7438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bar chart showing different size of \"Fully Paid\" vs. \"Charged Off\"\n",
    "df_text_desc['loan_status'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3851, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "In order to balance the classes, under-sample the majority class.\n",
    "Over-sampling the majority class can be done with SMOTE (Synthetic Minority Over-Sampling), \n",
    "but does not yield good results for high-dimensional, high-sparse datasets.  \n",
    "'''\n",
    "\n",
    "# Save Fully Paid (majority class) as separate dataframe.\n",
    "fully_paid = df_text_desc['loan_status'] == 'Fully Paid'\n",
    "df_fully_paid = df_text_desc[fully_paid]\n",
    "\n",
    "# Run pandas.sample method to use same number of samples as minority class.  \n",
    "num_samples = loan_status_desc[1]    # number of loans \"Charged Off\" (e.g. 3851)\n",
    "df_fp_undersample = df_fully_paid.sample(num_samples, random_state=1)  \n",
    "df_fp_undersample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3851, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save minority class as separate dataframe.\n",
    "charged_off = df_text_desc['loan_status'] == 'Charged Off'\n",
    "df_charged_off = df_text_desc[charged_off]\n",
    "df_charged_off.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7702, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the \"Fully Paid\" (under-sampled) and \"Charged Off\" into one dataframe\n",
    "bal_frames = [df_fp_undersample, df_charged_off]\n",
    "df_balanced = pd.concat(bal_frames)\n",
    "df_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d9afcf8cc0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEuCAYAAABoE64fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d9afcd2b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bar chart showing different size of \"Fully Paid\" vs. \"Charged Off\" (Balanced)\n",
    "df_balanced['loan_status'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X training size:  (6161,)\n",
      "y training size:  (6161,)\n",
      "X test size:  (1541,)\n",
      "y test size:  (1541,)\n"
     ]
    }
   ],
   "source": [
    "# Split the Content and Classes into train and test sets (20%).\n",
    "# To ensure that it splits it according to same class ratio, use \"stratify\" parameter.  \n",
    "X_train, X_test, y_train, y_test = train_test_split(df_balanced['desc'], df_balanced['loan_status'], \n",
    "                                                    random_state=1, test_size=0.2, stratify=df_balanced['loan_status'])\n",
    "\n",
    "# Print the size of each train and test datasets\n",
    "print('X training size: ', X_train.shape)\n",
    "print('y training size: ', y_train.shape)\n",
    "print('X test size: ', X_test.shape)\n",
    "print('y test size: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12060      Borrower added on 07/04/11 > I plan to use t...\n",
       "33900     575633 added on 11/18/09 > I plan on using th...\n",
       "29767      Borrower added on 05/23/10 > This loan if fu...\n",
       "39462    I hope to use the money to consolidate two cre...\n",
       "37935    Thank you for taking the time to consider my a...\n",
       "Name: desc, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train is the loan descriptions from 'desc' field (80% of total)\n",
    "X_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12060    Charged Off\n",
       "33900     Fully Paid\n",
       "29767     Fully Paid\n",
       "39462    Charged Off\n",
       "37935    Charged Off\n",
       "Name: loan_status, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_train is the class data, a.k.a. \"label data\" or \"target classes\" (80% of total)\n",
    "y_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The test_train_split output retains the data type as a panda series.  \n",
    "# Later we will run a list comprehension so this data, changing data type.\n",
    "# Either data type should work fine.\n",
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The test data represents 20% of the total.  X_test is loan descriptions, y_test is class data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fully Paid     771\n",
       "Charged Off    770\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the y_test value_counts to verify confusion matrix\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Vectorize Text into Document-Term-Matrix (no pre-processing)\n",
    "* Leave text unprocessed, no lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training dtm:  (6161, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a vectorizer for document-term-matrix\n",
    "vect = CountVectorizer(max_features=1000)\n",
    "\n",
    "# Fit the vectorizer object to the X_train text\n",
    "X_train_vect = vect.fit(X_train, y_train)\n",
    "\n",
    "# Transform the training text into a document-term-matrix\n",
    "X_train_dtm = X_train_vect.transform(X_train)\n",
    "\n",
    "print(\"Size of training dtm: \", X_train_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test dtm:  (1541, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Transform the test text into a document-term-matrix (input fed into models)\n",
    "X_test_dtm = X_train_vect.transform(X_test)\n",
    "\n",
    "print(\"Size of test dtm: \", X_test_dtm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2a: Vectorize Text into Document-Term-Matrix (with pre-processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing text  \n",
    "Using techniques from Kaggle tutorial  and Scikit-Learn Tutorial.  (See references at the top).\n",
    "1. Create process_chars function\n",
    "1. List comprehension applying function to data.\n",
    "1. Create a LemmaTokenizer class\n",
    "1. Instantiate CountVectorizer object with LemmaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Create process_chars function.\n",
    "\n",
    "# Use stopwords from NLTK, but also add individual letters.\n",
    "stop_nltk = stopwords.words(\"english\")\n",
    "stop_nltk_plus = stop_nltk + [u'a',u'b',u'c',u'd',u'e',u'f',u'g',u'h',u'i',u'j',\n",
    "                         u'k',u'l',u'm',u'n',u'o',u'p',u'q',u'r',u's',u't',\n",
    "                         u'u',u'v',u'w',u'x',u'y',u'z']\n",
    "# In Python, searching a set is much faster than searching\n",
    "# a list, so convert the stop words to a set.  \n",
    "# Use this \"steps\" set in the below function.  \n",
    "stops = set(stop_nltk_plus)\n",
    "    \n",
    "# function to process documents\n",
    "def process_chars(input_text):\n",
    "    # Remove non-letters, and make lowercase\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", input_text)\n",
    "        \n",
    "    # Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()    \n",
    "    \n",
    "    # Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    \n",
    "    # Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words ))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 2: List comprehension applying function to data.\n",
    "\n",
    "# Process the text of X_train.  Keep same name for simplicity.\n",
    "X_train = [process_chars(text_file) for text_file in X_train]\n",
    "\n",
    "# Process the text of X_train.  Keep same name for simplicity.\n",
    "X_test = [process_chars(text_file) for text_file in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 3: Create a LemmaTokenizer class.  \n",
    "# Based on Scikit-Learn \"Feature Extraction\" page.\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 4: Instantiate CountVectorizer object with LemmaTokenizer.\n",
    "# Based on Scikit-Learn \"Feature Extraction\" page.\n",
    "\n",
    "# instantiate CountVectorizer object, with LemmaTokenizer()\n",
    "count_vect_lemma = CountVectorizer(tokenizer=LemmaTokenizer(), ngram_range=(1, 2), max_features=400, \n",
    "                                   max_df=0.90, stop_words='english')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training dtm:  (6161, 400)\n",
      "Wall time: 11.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Size of training dtm:  (6161, 1000)\n",
    "# Wall time: 20.2 s\n",
    "\n",
    "\n",
    "# Fit the vectorizer object to the X_train text data\n",
    "X_train_vect = count_vect_lemma.fit(X_train)\n",
    "\n",
    "# Transform the training text into a document-term-matrix\n",
    "X_train_dtm = X_train_vect.transform(X_train)\n",
    "\n",
    "print(\"Size of training dtm: \", X_train_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test dtm:  (1541, 400)\n",
      "Wall time: 1.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Size of test dtm:  (1541, 1000)\n",
    "# Wall time: 2.12 s\n",
    "\n",
    "\n",
    "# Transform the test text into a document-term-matrix (input fed into models)\n",
    "X_test_dtm = X_train_vect.transform(X_test)\n",
    "\n",
    "print(\"Size of test dtm: \", X_test_dtm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2b: In addition to CountVectorizer, use TfidfTransformer\n",
    "Let's try 3 different options:\n",
    "1. TfidfTransformer(use_idf=True)\n",
    "1. TfidfTransformer(use_idf=False)\n",
    "1. Don't use TfidfTransformer at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6161, 400)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a TfidfTransformer object, fit the X_train_dtm data, save as object.\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_dtm)\n",
    "\n",
    "# Transform the X_train_dtm data to the TfidfTransformer.  \n",
    "# Could name is something else, but keeping same name for simplicity.\n",
    "X_train_dtm = tf_transformer.transform(X_train_dtm)\n",
    "\n",
    "# What is the shape of the document-term-matrix?  (Should be same.)\n",
    "X_train_dtm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2c: In addition to CountVectorizer, use TruncatedSVD\n",
    "TruncatedSVD used for dimensionality reduction, particular with sparse matrices (e.g. text matrices).\n",
    "\n",
    "When TruncatedSVD is used in conjunction with CountVectorizer and Tfidf, it is known as Latent Semantic Analysis (LSA).\n",
    "\n",
    "Scikit-Learn Documentation on TruncatedSVD\n",
    "> http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html\n",
    "<br>\n",
    "><br>http://scikit-learn.org/stable/modules/decomposition.html\n",
    "<br>\n",
    "><br>http://scikit-learn.org/stable/auto_examples/text/document_clustering.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD()\n",
    "\n",
    "normalizer = Normalizer(copy=True)\n",
    "\n",
    "lsa = make_pipeline(svd, normalizer)\n",
    "\n",
    "X_train_dtm = lsa.fit_transform(X_train_dtm)\n",
    "\n",
    "X_test_dtm = lsa.transform(X_test_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 3: Vectorize Text Using Hashing Vectorizer\n",
    "Usually HashingVectorizer is used to vectorize text documents that do not fit in memory.  But maybe it can be used as a dimensionality reduction technique, and improve prediction accuracy.\n",
    "<br>\n",
    "<br>Scikit-Learn Documentation on HashingVectorizer:\n",
    ">http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html#sklearn.feature_extraction.text.HashingVectorizer\n",
    "<br>\n",
    "><br>http://scikit-learn.org/stable/auto_examples/text/document_clustering.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Perform an IDF normalization on the output of HashingVectorizer\n",
    "hasher = HashingVectorizer(n_features=400,tokenizer=LemmaTokenizer(),\n",
    "                           stop_words='english', non_negative=True,\n",
    "                           norm=None, binary=False)\n",
    "\n",
    "# Vectorizer uses pipeline to combine hasher and TfidfTransformer\n",
    "vectorizer = make_pipeline(hasher, TfidfTransformer(use_idf=False))\n",
    "\n",
    "# Create X_train_dtm\n",
    "X_train_dtm = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Create X_test_dtm\n",
    "X_test_dtm = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 4: Text Classification with Word2Vec\n",
    "http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# An idea to explore in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification Example Without GridSearchCV\n",
    "* In practice, the GridSearchCV class accomplishes same result, while tuning combinations of model parameters.\n",
    "* But to make it simpler to follow the workflow, here is an example of text classification step-by-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step 1: Instatiate a classifier object.\n",
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "# Step 2: \"Fit\" training data onto model, both data and labels.\n",
    "# The machine is \"learning\" how the training words match the label data (or \"classes\").  \n",
    "rf_clf.fit(X_train_dtm, y_train)\n",
    "\n",
    "# Step 3: Predict test data using model, only data (not labels)\n",
    "# Store results as predictions on test data ... next we will compare with real labels.  \n",
    "rf_test_predictions = rf_clf.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier: \n",
      "0.523036988968\n",
      "\n",
      "Confusion Matrix: \n",
      "(rows are actual, columns are predictions)\n",
      "[[486 284]\n",
      " [451 320]]\n",
      "\n",
      "Classification Report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Charged Off       0.52      0.63      0.57       770\n",
      " Fully Paid       0.53      0.42      0.47       771\n",
      "\n",
      "avg / total       0.52      0.52      0.52      1541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Classifier: \")\n",
    "\n",
    "# print accuracy of class predictions\n",
    "print(metrics.accuracy_score(y_test, rf_test_predictions))\n",
    "\n",
    "# print the confusion matrix\n",
    "print(\"\\nConfusion Matrix: \")\n",
    "print(\"(rows are actual, columns are predictions)\")\n",
    "print(metrics.confusion_matrix(y_test, rf_test_predictions, labels=[\"Charged Off\", \"Fully Paid\"]))\n",
    "\n",
    "# print the Classification Report\n",
    "print(\"\\nClassification Report: \")\n",
    "print(metrics.classification_report(y_test, rf_test_predictions,target_names=[\"Charged Off\", \"Fully Paid\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Technique #1: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.538711248174\n",
      "bootstrap: True\n",
      "class_weight: 'balanced'\n",
      "n_estimators: 100\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 0.546664502516\n",
    "# bootstrap: True\n",
    "# class_weight: 'balanced'\n",
    "# n_estimators: 50\n",
    "# Wall time: 57.5 s\n",
    "\n",
    "# Use GridSearchCV to tune model parameters\n",
    "\n",
    "# parameters \n",
    "parameters_rf = {'n_estimators': (10, 50, 100),                 # default 10\n",
    "                 'bootstrap': (True, False),                    # default true\n",
    "                  'class_weight': ('balanced', None)}           # default None\n",
    "\n",
    "# instantiate a classifier object\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# instantiate a GridSearchCV object\n",
    "gs_rf = GridSearchCV(rf, parameters_rf, n_jobs=-1)\n",
    "\n",
    "# fit the GridSearchCV object to the training data\n",
    "gs_rf = gs_rf.fit(X_train_dtm, y_train)\n",
    "\n",
    "print(gs_rf.best_score_)\n",
    "\n",
    "for param_name in sorted(parameters_rf.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_rf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier: \n",
      "0.543153796236\n",
      "[[430 340]\n",
      " [364 407]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Charged Off       0.54      0.56      0.55       770\n",
      " Fully Paid       0.54      0.53      0.54       771\n",
      "\n",
      "avg / total       0.54      0.54      0.54      1541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Classifier: \")\n",
    "\n",
    "# predict classification\n",
    "gs_rf_test_predictions = gs_rf.predict(X_test_dtm)\n",
    "\n",
    "# print accuracy of class predictions\n",
    "print(metrics.accuracy_score(y_test, gs_rf_test_predictions))\n",
    "\n",
    "# print the confusion matrix\n",
    "print(metrics.confusion_matrix(y_test, gs_rf_test_predictions))\n",
    "\n",
    "print(metrics.classification_report(y_test, gs_rf_test_predictions,target_names=[\"Charged Off\", \"Fully Paid\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification Technique #2: Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search for MultinomialNB\n",
      "Accuracy:  0.541470540497\n",
      "alpha:  0.1\n",
      "fit_prior:  False\n",
      "Wall time: 6.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Use GridSearchCV to tune model parameters\n",
    "\n",
    "# Grid Search for MultinomialNB\n",
    "# Accuracy:  0.561434832008\n",
    "# alpha:  1.0\n",
    "# fit_prior:  True\n",
    "# Wall time: 6.71 s\n",
    "    \n",
    "# parameters for MultinomialNB\n",
    "parameters_mnb = {'alpha': (0.001, 0.01, 0.1, 1.0, 10.0, 100.0),\n",
    "                 'fit_prior': (True, False)}    # default is True, use uniform if False\n",
    "\n",
    "# instantiate a MultinomialNB object\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# instantiate a GridSearchCV object\n",
    "gs_mnb = GridSearchCV(mnb, parameters_mnb, n_jobs=-1)\n",
    "\n",
    "# fit the GridSearchCV object to the training data\n",
    "gs_mnb = gs_mnb.fit(X_train_dtm, y_train)\n",
    "\n",
    "print(\"Grid Search for MultinomialNB\")\n",
    "print(\"Accuracy: \", gs_mnb.best_score_)\n",
    "print(\"alpha: \", gs_mnb.best_params_['alpha'])\n",
    "print(\"fit_prior: \", gs_mnb.best_params_['fit_prior'])\n",
    "# for param_name in sorted(parameters.keys()):\n",
    "#     print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes: \n",
      "0.550940947437\n",
      "[[394 376]\n",
      " [316 455]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Charged Off       0.55      0.51      0.53       770\n",
      " Fully Paid       0.55      0.59      0.57       771\n",
      "\n",
      "avg / total       0.55      0.55      0.55      1541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Multinomial Naive Bayes: \")\n",
    "\n",
    "# predict classification\n",
    "gs_mnb_test_predictions = gs_mnb.predict(X_test_dtm)\n",
    "\n",
    "# print accuracy of class predictions\n",
    "print(metrics.accuracy_score(y_test, gs_mnb_test_predictions))\n",
    "\n",
    "# print the confusion matrix\n",
    "print(metrics.confusion_matrix(y_test, gs_mnb_test_predictions))\n",
    "\n",
    "# print classification report\n",
    "print(metrics.classification_report(y_test, gs_mnb_test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare Target Class Label Counts to Classification Report\n",
      "0: Ham, 1: Spam\n",
      "\n",
      "Charged Off    770\n",
      "Fully Paid     771\n",
      "Name: loan_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verify classes against the y_test data\n",
    "print(\"Compare Target Class Label Counts to Classification Report\")\n",
    "print(\"0: Ham, 1: Spam\\n\")\n",
    "print(y_test.value_counts(ascending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Technique #3: Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.537899691609\n",
      "alpha: 0.01\n",
      "class_weight: None\n",
      "penalty: None\n",
      "Wall time: 6.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Use GridSearchCV to tune model parameters\n",
    "\n",
    "# 0.949720670391\n",
    "# alpha: 0.01\n",
    "# class_weight: 'balanced'\n",
    "# penalty: 'elasticnet'\n",
    "# Wall time: 23 s\n",
    "\n",
    "# parameters for SVM\n",
    "parameters_svm = {'penalty': (None, 'l1', 'l2', 'elasticnet'),  # default is 'l2'\n",
    "                  'alpha': (0.0001, 0.01, 1.0),                 # default 0.0001\n",
    "                  'class_weight': ('balanced', None)}           # default None\n",
    "\n",
    "# instantiate a SVM object\n",
    "svm = SGDClassifier(loss='hinge', random_state=42)\n",
    "\n",
    "# instantiate a GridSearchCV object\n",
    "gs_svm = GridSearchCV(svm, parameters_svm, n_jobs=-1)\n",
    "\n",
    "# fit the GridSearchCV object to the training data\n",
    "gs_svm = gs_svm.fit(X_train_dtm, y_train)\n",
    "\n",
    "print(gs_svm.best_score_)\n",
    "\n",
    "for param_name in sorted(parameters_svm.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_svm.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machines: \n",
      "0.550940947437\n",
      "[[412 358]\n",
      " [334 437]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Charged Off       0.55      0.54      0.54       770\n",
      " Fully Paid       0.55      0.57      0.56       771\n",
      "\n",
      "avg / total       0.55      0.55      0.55      1541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Support Vector Machines: \")\n",
    "\n",
    "# predict classification\n",
    "gs_svm_test_predictions = gs_svm.predict(X_test_dtm)\n",
    "\n",
    "# print accuracy of class predictions\n",
    "print(metrics.accuracy_score(y_test, gs_svm_test_predictions))\n",
    "\n",
    "# print the confusion matrix\n",
    "print(metrics.confusion_matrix(y_test, gs_svm_test_predictions))\n",
    "\n",
    "print(metrics.classification_report(y_test, gs_svm_test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Technique #4: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.540009738679\n",
      "C: 0.01\n",
      "class_weight: None\n",
      "penalty: 'l2'\n",
      "Wall time: 7.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Use GridSearchCV to tune model parameters\n",
    "\n",
    "# 0.95530726257\n",
    "# C: 1.0\n",
    "# class_weight: None\n",
    "# penalty: 'l2'\n",
    "# Wall time: 5.55 s\n",
    "\n",
    "# parameters \n",
    "parameters_lr = {'penalty': ('l1', 'l2'),               # default is 'l2'\n",
    "                  'C': (0.01, 1.0, 10.0, 100.0),            # default 1.0\n",
    "                  'class_weight': ('balanced', None)}                         # default None\n",
    "\n",
    "# instantiate a LogisticRegression object\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# instantiate a GridSearchCV object\n",
    "gs_lr = GridSearchCV(lr, parameters_lr, n_jobs=-1)\n",
    "\n",
    "# fit the GridSearchCV object to the training data\n",
    "gs_lr = gs_lr.fit(X_train_dtm, y_train)\n",
    "\n",
    "print(gs_lr.best_score_)\n",
    "\n",
    "for param_name in sorted(parameters_lr.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_lr.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: \n",
      "0.565217391304\n",
      "[[432 338]\n",
      " [332 439]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Charged Off       0.57      0.56      0.56       770\n",
      " Fully Paid       0.56      0.57      0.57       771\n",
      "\n",
      "avg / total       0.57      0.57      0.57      1541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression: \")\n",
    "\n",
    "# predict classification\n",
    "gs_lr_test_predictions = gs_lr.predict(X_test_dtm)\n",
    "\n",
    "# print accuracy of class predictions\n",
    "print(metrics.accuracy_score(y_test, gs_lr_test_predictions))\n",
    "\n",
    "# print the confusion matrix\n",
    "print(metrics.confusion_matrix(y_test, gs_lr_test_predictions))\n",
    "\n",
    "print(metrics.classification_report(y_test, gs_lr_test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Models (w/o Pre-Processing, with GridSearch)\n",
    "Option 1: Vectorize Text into Document-Term-Matrix (no pre-processing)\n",
    "\n",
    "(Precision, Recall, F1-Score for the \"Charged Off\" Class Only)\n",
    "\n",
    "| Model                    | Accuracy   | Precision    | Recall    | F1-Score    |          \n",
    "|--------------------------|------------|--------------|-----------|-------------|          \n",
    "| Random Forest            | 0.5665     | 0.56         | 0.59      | 0.58        |          \n",
    "| Multinomial Naive Bayes  | 0.5840     | 0.59         | 0.56      | 0.57        |          \n",
    "| Support Vector Machines  | 0.5827     | 0.58         | 0.60      | 0.59        |          \n",
    "| Logistic Regression      | 0.5840     | 0.59         | 0.57      | 0.58        |          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Models (with Pre-Processing, with GridSearch)\n",
    "Option 2a: Vectorize Text into Document-Term-Matrix (with pre-processing)\n",
    "\n",
    "(Precision, Recall, F1-Score for the \"Charged Off\" Class Only)\n",
    "\n",
    "| Model                    | Accuracy   | Precision    | Recall    | F1-Score    |          \n",
    "|--------------------------|------------|--------------|-----------|-------------|          \n",
    "| Random Forest            | 0.5775     | 0.57         | 0.60      | 0.59        |          \n",
    "| Multinomial Naive Bayes  | 0.5749     | 0.57         | 0.59      | 0.57        |          \n",
    "| Support Vector Machines  | 0.5483     | 0.54         | 0.59      | 0.57        |          \n",
    "| Logistic Regression      | 0.5737     | 0.57         | 0.59      | 0.58        |          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2b: In addition to CountVectorizer, use TfidfTransformer(use_idf=True)\n",
    "\n",
    "(Precision, Recall, F1-Score for the \"Charged Off\" Class Only)\n",
    "\n",
    "| Model                    | Accuracy   | Precision    | Recall    | F1-Score    |          \n",
    "|--------------------------|------------|--------------|-----------|-------------|          \n",
    "| Random Forest            | 0.5042     | 0.50         | 0.49      | 0.50        |          \n",
    "| Multinomial Naive Bayes  | 0.5749     | 0.57         | 0.59      | 0.57        |          \n",
    "| Support Vector Machines  | 0.5483     | 0.54         | 0.59      | 0.57        |          \n",
    "| Logistic Regression      | 0.5737     | 0.57         | 0.59      | 0.58        |   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 3: Vectorize Text Using Hashing Vectorizer\n",
    "\n",
    "(Precision, Recall, F1-Score for the \"Charged Off\" Class Only)\n",
    "\n",
    "| Model                    | Accuracy   | Precision    | Recall    | F1-Score    |          \n",
    "|--------------------------|------------|--------------|-----------|-------------|          \n",
    "| Random Forest            | 0.5432     | 0.54         | 0.56      | 0.55        |          \n",
    "| Multinomial Naive Bayes  | 0.5509     | 0.55         | 0.51      | 0.53        |          \n",
    "| Support Vector Machines  | 0.5509     | 0.55         | 0.54      | 0.54        |          \n",
    "| Logistic Regression      | 0.5652     | 0.57         | 0.56      | 0.56        |   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
